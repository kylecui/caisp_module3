{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 tokens Let's to go <eos>\n",
    "# 4 chinese tokens 我 出发 去 <eos>\n",
    "\n",
    "input_lets = np.array([1.87, 1.09])\n",
    "input_go = np.array([-1.68, 0.67])\n",
    "\n",
    "output_chufa = np.array([-0.86, 2.37])\n",
    "output_eos = np.array([2.7, -0.34])\n",
    "\n",
    "\n",
    "W_q_encoder = np.array([[ 1.1, -2.8], \n",
    "                        [ 0.6,  2.4]])\n",
    "W_k_encoder = np.array([[-1.7, -1.4],\n",
    "                        [ 0.5,  0.9]])\n",
    "W_v_encoder = np.array([[ 1.5, -0.3],\n",
    "                        [-1.0, -0.2]])\n",
    "\n",
    "# Train encoder \n",
    "q_1_encoder = np.dot(W_q_encoder, input_lets)\n",
    "q_2_encoder = np.dot(W_q_encoder, input_go)\n",
    "k_1_encoder = np.dot(W_k_encoder, input_lets)\n",
    "k_2_encoder = np.dot(W_k_encoder, input_go)\n",
    "v_1_encoder = np.dot(W_v_encoder, input_lets)\n",
    "v_2_encoder = np.dot(W_v_encoder, input_go)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.995  3.738]\n",
      "[-3.724  0.6  ]\n",
      "[-4.705  1.916]\n",
      "[ 1.918 -0.237]\n",
      "[ 2.478 -2.088]\n",
      "[-2.721  1.546]\n"
     ]
    }
   ],
   "source": [
    "print(q_1_encoder)\n",
    "print(q_2_encoder)\n",
    "print(k_1_encoder)\n",
    "print(k_2_encoder)\n",
    "print(v_1_encoder)\n",
    "print(v_2_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.843483 -2.794316]\n"
     ]
    }
   ],
   "source": [
    "qk_encoder_1 = np.array([np.dot(q_1_encoder, k_1_encoder.T), np.dot(q_1_encoder, k_2_encoder.T)])\n",
    "print(qk_encoder_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.99999561e-01 4.39424711e-07]\n",
      "[ 2.47799772 -2.0879984 ]\n"
     ]
    }
   ],
   "source": [
    "softmax_qk_encoder_1 = softmax(qk_encoder_1)\n",
    "print(softmax_qk_encoder_1)\n",
    "output_encoder_1 = np.dot(softmax_qk_encoder_1, np.array([v_1_encoder, v_2_encoder]))\n",
    "print(output_encoder_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.67102  -7.284832]\n"
     ]
    }
   ],
   "source": [
    "qk_encoder_2 = np.array([np.dot(q_2_encoder, k_1_encoder.T), np.dot(q_2_encoder, k_2_encoder.T)])\n",
    "print(qk_encoder_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 5.3396981e-12]\n",
      "[ 2.478 -2.088]\n"
     ]
    }
   ],
   "source": [
    "softmax_qk_encoder_2 = softmax(qk_encoder_2)\n",
    "print(softmax_qk_encoder_2)\n",
    "output_encoder_2 = np.dot(softmax_qk_encoder_2, np.array([v_1_encoder, v_2_encoder]))\n",
    "print(output_encoder_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.34799772 -0.9979984 ]\n",
      "[ 0.798 -1.418]\n"
     ]
    }
   ],
   "source": [
    "resi_encoder_1 = output_encoder_1 + input_lets\n",
    "resi_encoder_2 = output_encoder_2 + input_go\n",
    "print(resi_encoder_1)\n",
    "print(resi_encoder_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.182 1.046]\n",
      "[ 1.216 -1.992]\n",
      "[-2.834 -2.332]\n"
     ]
    }
   ],
   "source": [
    "W_q_decoder = np.array([[ 0.4, -0.3],\n",
    "                        [ 0.4,  0.1]])\n",
    "W_k_decoder = np.array([[ 0.4, -0.4],\n",
    "                        [-0.7,  0.3]])\n",
    "W_v_decoder = np.array([[-1.1, -0.4],\n",
    "                        [-0.7,  1.3]])\n",
    "\n",
    "# Train decoder\n",
    "q_eos_decoder = np.dot(W_q_decoder, output_eos)\n",
    "k_eos_decoder = np.dot(W_k_decoder, output_eos)\n",
    "v_eos_decoder = np.dot(W_v_decoder, output_eos)\n",
    "print(q_eos_decoder)\n",
    "print(k_eos_decoder)\n",
    "print(v_eos_decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "[-2.834 -2.332]\n",
      "[-0.134 -2.672]\n"
     ]
    }
   ],
   "source": [
    "softmax_q_eos_decoder = softmax(np.array([np.dot(q_eos_decoder, k_eos_decoder.T)]))\n",
    "print(softmax_q_eos_decoder)\n",
    "output_decoder_1_eos = softmax_q_eos_decoder * v_eos_decoder\n",
    "print(output_decoder_1_eos)\n",
    "\n",
    "resi_decoder_1_eos = output_decoder_1_eos + output_eos\n",
    "print(resi_decoder_1_eos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0026 -2.6318]\n",
      "[-4.48339797  2.10279804]\n",
      "[-0.4524  1.3738]\n",
      "[0.89310924 0.10689076]\n",
      "[5.98039557 3.10779783]\n",
      "[2.5794 1.1878]\n",
      "[5.61686057 2.9025678 ]\n",
      "[5.48286057 0.2305678 ]\n",
      "[4.86988785e-05 9.99774851e-01 1.39017150e-04 3.74331197e-05]\n"
     ]
    }
   ],
   "source": [
    "W_q_decoder_2 = np.array([[ 1.5,  0.3],\n",
    "                          [-0.3,  1.0]])\n",
    "W_k_encoder_2 = np.array([[-1.1, -0.3],\n",
    "                          [ 0.3, -0.8]])\n",
    "W_v_encoder_2 = np.array([[ 1.1, -1.2],\n",
    "                          [ 0.6, -0.5]])\n",
    "\n",
    "q_eos_decoder_2 = np.dot(W_q_decoder_2, resi_decoder_1_eos)\n",
    "print(q_eos_decoder_2)\n",
    "\n",
    "\n",
    "k_1_encoder_2 = np.dot(W_k_encoder_2, resi_encoder_1)\n",
    "k_2_encoder_2 = np.dot(W_k_encoder_2, resi_encoder_2)\n",
    "print(k_1_encoder_2)\n",
    "print(k_2_encoder_2)\n",
    "\n",
    "\n",
    "softmax_q_eos_decoder_2 = softmax(np.array([np.dot(q_eos_decoder_2, k_1_encoder_2.T), np.dot(q_eos_decoder_2, k_2_encoder_2.T)]))\n",
    "print(softmax_q_eos_decoder_2)\n",
    "\n",
    "\n",
    "v_1_encoder_2 = np.dot(W_v_encoder_2, resi_encoder_1)\n",
    "v_2_encoder_2 = np.dot(W_v_encoder_2, resi_encoder_2)\n",
    "print(v_1_encoder_2)\n",
    "print(v_2_encoder_2)\n",
    "\n",
    "output_decoder_2_eos = np.dot(softmax_q_eos_decoder_2, np.array([v_1_encoder_2, v_2_encoder_2]))\n",
    "print(output_decoder_2_eos)\n",
    "\n",
    "resi_decoder_2_eos = output_decoder_2_eos + resi_decoder_1_eos\n",
    "print(resi_decoder_2_eos)\n",
    "\n",
    "word_array_output = np.array([[-0.6, -2.0],\n",
    "                              [ 0.8, -0.9],\n",
    "                              [-0.1, -1.1],\n",
    "                              [-1.0,  1.6]])\n",
    "bias_output = np.array([-0.6, 1.4, -2.5, 0.5]).T\n",
    "first_output = softmax(np.dot(word_array_output, resi_decoder_2_eos) + bias_output)\n",
    "print(first_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
